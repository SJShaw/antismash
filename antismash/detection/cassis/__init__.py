# License: GNU Affero General Public License v3 or later
# A copy of GNU AGPL v3 should have been included in this software package in LICENSE.txt.

"""Implementation of the CASSIS method for the motif-based prediction of SM gene clusters"""

from collections import defaultdict
import csv
import logging
import os
import shutil
from typing import Any, Dict, List, Optional, Set, Tuple
from xml.etree import cElementTree as ElementTree

from Bio import SeqIO
from Bio.SeqRecord import SeqRecord
from Bio.SeqFeature import SeqFeature

from antismash.common import path, module_results
from antismash.common.secmet.feature import ClusterBorder, Feature, FeatureLocation, GeneFunction, Gene
from antismash.common.secmet.record import Record
from antismash.config.args import ModuleArgs

from .runners import run_fimo, run_meme
from .promoters import Promoter, CombinedPromoter, get_promoters, DuplicatePromoterError, \
                       write_promoters_to_file

NAME = "cassis"
SHORT_DESCRIPTION = "Detect secondary metabolite gene cluster (motif based)"

MAX_PERCENTAGE = 14.  # the maximum percentage of promoters sharing a motif
MAX_GAP_LENGTH = 2  # the maximum gap length between islands

VERBOSE_DEBUG = False  # whether to show all debugging info or not


class CassisResults(module_results.ModuleResults):
    """ Contains the borders predicted by cassis """
    def __init__(self, record_id: str, borders: List[ClusterBorder]) -> None:
        super().__init__(record_id)
        self.borders = borders

    def to_json(self, *args) -> Dict[str, Any]:
        return {}

    @staticmethod
    def from_json(*args) -> "CassisResults":
        return None

    def add_to_record(self, record) -> None:
        pass

    def get_predictions(self) -> List[ClusterBorder]:
        return self.borders


def get_arguments() -> ModuleArgs:
    """ Build and return arguments. No extra options beyond a switch to enable """
    args = ModuleArgs('Additional analysis', 'cassis')
    args.add_analysis_toggle('--cassis',
                             dest='cassis',
                             action='store_true',
                             default=False,
                             help="Motif based prediction of SM gene clusters.")
    return args


def is_enabled(options) -> bool:
    """ Is the module enabled """
    return options.cassis


def check_options(options) -> List[str]:
    """ Make sure the options are sane """
    problems = []
    if options.taxon != "fungi" and is_enabled(options):
        problems.append("CASSIS cluster border prediction only works for fungal sequences.")
    return problems


def regenerate_previous_results(previous, record: Record, options):
    """ Rebuild the previous run results from a JSON object into this module's
        python results class.

        Arguments:
            previous: the previous results as a dictionary
            record: the Record that was used to generate the previous results
            options: an antismash.Config object
    """
    logging.critical("always skipping results regeneration for cassis")
    return None


def run_on_record(record: Record, results, options):
    """ Run this module's analysis section on the given record or use the
        previous results.

        Arguments:
            record: the Record instance to analyse
            results: the previous results as generated by regenerate_previous_results()
            options: an antismash.Config object

        Returns:
            this module's results as a subclass of
                antismash.common.module_results.ModuleResults
    """
    borders = detect(record, options)
    logging.debug("Cassis detected %d cluster border(s)", len(borders))
    for border in borders:
        record.add_cluster_border(border)
    return CassisResults(record.id, borders)


class InvalidLocationError(Exception):
    '''Thrown when running into invalid gene locations during runtime'''
    pass


class Pairing:
    """ A common component throughout CASSIS is a range given by number of
        promoters upstream and number of promoters downstream. This base class
        is used to reduce duplication and simplify string generation for labels.
    """
    def __init__(self, plus: int, minus: int) -> None:
        self.plus = int(plus)
        self.minus = int(minus)

    @property
    def pairing_string(self) -> str:
        """ A string representing the range of this pairing. """
        return "+{:02d}_-{:02d}".format(self.plus, self.minus)

    def __str__(self) -> str:
        return self.pairing_string


# all possible promoter sets for motif detection
# plus --> include <plus> promoters downstream the anchor gene's promoter
# minus --> include <minus> promoters upstream the anchor gene's promoter
PROMOTER_RANGE = [Pairing(plus, minus) for plus in range(16) for minus in range(16) if plus + minus >= 3]


def check_prereqs():
    """Check for prerequisites"""
    failure_messages = []
    for binary_name, _ in [("meme", "4.11.1"), ("fimo", "4.11.1")]:
        if path.locate_executable(binary_name) is None:
            failure_messages.append("Failed to locate executable for {!r}".format(binary_name))
        # TODO: Check binary version here

    return failure_messages


class Motif(Pairing):
    """ An individual motif, tracks a location as a plus/minus pair, an evalue (score)
        and any hits.
    """
    def __init__(self, plus: int, minus: int, score: Optional[float] = None,
                 hits: Optional[Dict[str, int]] = None) -> None:
        super().__init__(plus, minus)
        self._score = None  # type: Optional[float]
        if score:
            self.score = score
        self.seqs = []  # type: List[str]
        self.hits = defaultdict(lambda: 0)  # type: Dict[str, int]
        if hits:
            for key, val in hits.items():
                self.hits[str(key)] = int(val)

    @property
    def score(self) -> Optional[float]:
        """ The score/evalue of a motif """
        return self._score

    @score.setter
    def score(self, score: float):
        self._score = float(score)

    def __eq__(self, other: Any) -> bool:
        return (isinstance(other, Motif)
                and self.plus == other.plus
                and self.minus == other.minus
                and self._score == other.score
                and self.seqs == other.seqs
                and self.hits == other.hits)

    def __repr__(self) -> str:
        return "Motif(%s, score=%s, hits=%s)" % (self.pairing_string, self.score, self.hits)


class Island:
    """ A container for an island between two promoters with a motif. """
    def __init__(self, start: Promoter, end: Promoter, motif: Motif) -> None:
        assert isinstance(start, Promoter)
        self.start = start
        assert isinstance(end, Promoter)
        self.end = end
        assert isinstance(motif, Motif)
        self.motif = motif

    def __eq__(self, other: Any) -> bool:
        return (isinstance(other, Island)
                and self.start == other.start
                and self.end == other.end
                and self.motif == other.motif)

    def __repr__(self) -> str:
        return "Island(start=%s, end=%s, motif=%s)" % (self.start, self.end, self.motif)


def detect(record: Record, options) -> List[ClusterBorder]:
    """Use core genes (anchor genes) from hmmdetect as seeds to detect gene clusters"""
    logging.info("Detecting gene clusters using CASSIS")

    # get core genes from hmmdetect --> necessary CASSIS input, aka "anchor genes"
    anchor_gene_names = get_anchor_gene_names(record)
    logging.info("Record has %d anchor genes", len(anchor_gene_names))
    if not anchor_gene_names:
        return []

    # filter all genes in record for neighbouring genes with overlapping annotations
    genes = record.get_genes()
    logging.info("Record has %d features of type 'gene'", len(genes))
    if not genes:
        return []
    genes, ignored_genes = ignore_overlapping(genes)

    # compute promoter sequences/regions --> necessary for motif prediction (MEME and FIMO input)
    try:
        # why these values? see "Wolf et al (2015): CASSIS and SMIPS ..."
        upstream_tss = 1000  # nucleotides upstream TSS
        downstream_tss = 50  # nucleotides downstream TSS
        promoters = get_promoters(record, genes, upstream_tss, downstream_tss)
        write_promoters_to_file(options.output_dir, record.name, promoters)
    except (InvalidLocationError, DuplicatePromoterError):
        logging.error("CASSIS discovered an error while working on the promoter sequences, skipping CASSIS analysis")
        return []

    if not promoters:
        logging.debug("CASSIS found zero promoter regions, skipping CASSIS analysis")
        return []
    elif len(promoters) < 3:
        logging.debug("Sequence %r yields less than 3 promoter regions, skipping CASSIS analysis", record.name)
        return []
    elif len(promoters) < 40:
        logging.debug("Sequence %r yields only %d promoter regions", record.name, len(promoters))
        logging.debug("Cluster detection on small sequences may lead to incomplete cluster predictions")

    store_promoters(promoters, record)

    predicted_borders = []
    cluster_predictions = {}  # {anchor gene: cluster predictions}
    for i, anchor in enumerate(anchor_gene_names):
        logging.debug("Detecting cluster around anchor gene %r (%d of %d)", anchor, i + 1, len(anchor_gene_names))

        try:
            anchor_promoter_index = get_anchor_promoter_index(anchor, promoters)
        except ValueError:
            logging.debug("No promoter region for %r, skipping this anchor gene", anchor)
            continue

        # predict motifs with MEME ("de novo")
        meme_dir = os.path.join(options.output_dir, "meme", anchor)
        promoter_sets = get_promoter_sets(meme_dir, anchor_promoter_index, promoters)
        exit_code = run_meme(meme_dir, options, VERBOSE_DEBUG)
        if exit_code != 0:
            logging.warning("MEME discovered a problem (exit code %d), skipping this anchor gene", exit_code)
            continue
        motifs = filter_meme_results(meme_dir, promoter_sets, anchor)

        if not motifs:
            logging.debug("Could not predict motifs around %r, skipping this anchor gene", anchor)
            continue

        # search motifs with FIMO ("scanning")
        fimo_dir = os.path.join(options.output_dir, "fimo", anchor)
        exit_code = run_fimo(meme_dir, fimo_dir, record, options, VERBOSE_DEBUG)
        if exit_code != 0:
            logging.warning("FIMO discovered a problem (exit code %d), skipping this anchor gene", exit_code)
            continue
        motifs = filter_fimo_results(motifs, fimo_dir, promoters, anchor_promoter_index)

        if not motifs:
            logging.debug("Could not find motif occurrences for %r, skipping this anchor gene", anchor)
            continue

        # TODO: as4, SiTaR (http://bioinformatics.oxfordjournals.org/content/27/20/2806):
        # Alternative to MEME and FIMO. Part of the original CASSIS implementation.
        # No motif prediction (no MEME). Motif search with SiTaR (instead if FIMO).
        # Have to provide a file in FASTA format with binding site sequences of at least one transcription factor.
        # Will result in binding sites per promoter (like FIMO) --> find islands
        #
        # implement: YES? NO?

        # find islands of binding sites around anchor gene
        islands = get_islands(anchor_promoter_index, motifs, promoters)
        logging.debug("%d possible cluster predictions for %r", len(islands), anchor)

        # return cluster predictions sorted by border abundance
        # (most abundant --> "best" prediction)
        cluster_predictions[anchor] = sort_by_abundance(islands)
        cluster_predictions[anchor] = check_cluster_predictions(cluster_predictions[anchor],
                                                                record, promoters, ignored_genes)

        predicted_borders.extend(create_cluster_borders(anchor, cluster_predictions[anchor], record))

    logging.debug("Cleaning up MEME and FIMO output directories")
    cleanup_outdir(anchor_gene_names, cluster_predictions, options)
    return predicted_borders


# additional methods
def get_anchor_gene_names(record: Record) -> List[str]:
    """ Finds all gene names that have a CDS with secondary metabolite
        annotations.

        Requires that a CDS.get_name() returns the same name of its parent
        Gene.get_name()

        Arguments:
            record: the record to search

        Returns:
            a list of gene names
    """
    anchor_genes = []

    for feature in record.get_cds_features():
        if feature.gene_function == GeneFunction.CORE:
            anchor_genes.append(feature.get_name())

    return anchor_genes


def ignore_overlapping(genes):
    """Ignore genes with overlapping locations (skip the second gene of an overlapping couple)"""
    ignored = []

    overlap = True
    while overlap:  # check again until we didn't find any overlap in the entire (remaining) gene list
        overlap = False
        non_overlapping = [genes[0]]

        for i in range(1, len(genes)):
            if genes[i-1].overlaps_with(genes[i]):
                logging.debug("Ignoring %r (overlapping with %r)",
                             genes[i].get_name(), genes[i-1].get_name())
                ignored.append(genes[i])
                overlap = True
            else:
                non_overlapping.append(genes[i])

        genes = non_overlapping

    if ignored:
        logging.debug("Ignoring %d genes due to overlapping locations", len(ignored))

    return (genes, ignored)


def get_anchor_promoter_index(anchor: str, promoters: List[Promoter]) -> int:
    """Find the name of the promoter which includes the anchor gene"""
    # the promoter ID is not (necessarily) equal to the anchor ID!
    for i, promoter in enumerate(promoters):
        if anchor in promoter.get_gene_names():
            return i

    raise ValueError("No promoter exists for the given anchor: %s" % anchor)


def get_promoter_sets(meme_dir: str, anchor_promoter: int, promoters: List[Promoter]) -> List[Motif]:
    """Prepare sets of promoter sequences and motif subdirectories"""
    promoter_sets = []

    if not os.path.exists(meme_dir):
        os.makedirs(meme_dir)

    # prepare sets of promoter sequences (MEME input)
    indices = set()  # type: Set[Tuple[int, int]] # to monitor unique start_index/end_index
    for pm in PROMOTER_RANGE:
        start_index = anchor_promoter - pm.minus
        end_index = anchor_promoter + pm.plus

        if start_index < 0:  # anchor promoter near beginning of record --> truncate
            if VERBOSE_DEBUG:
                logging.debug("Promoter set " + pm.pairing_string + " exceeds upstream record border")
            start_index = 0

        if end_index > len(promoters) - 1:  # anchor promoter near end of record --> truncate
            if VERBOSE_DEBUG:
                logging.debug("Promoter set " + pm.pairing_string + " exceeds downstream record border")
            end_index = len(promoters) - 1

        # discard promoter sets, which reappear due to truncation
        if (start_index, end_index) not in indices:
            indices.add((start_index, end_index))

            # check (again, compare init of PROMOTER_RANGE) if the promoter set has at least 4 promoters
            if end_index - start_index + 1 >= 4:
                promoter_sets.append(Motif(pm.plus, pm.minus))

                pm_dir = os.path.join(meme_dir, pm.pairing_string)
                if not os.path.exists(pm_dir):
                    os.makedirs(pm_dir)

                # write promoter sequences to fasta file, in respective "plus-minus" subdir
                with open(os.path.join(pm_dir, "promoters.fasta"), "w") as pm_handle:
                    for i in range(start_index, end_index + 1):
                        seq = SeqRecord(promoters[i].seq,
                                        id=promoters[i].get_id(),
                                        description="length={}bp".format(len(promoters[i].seq)))
                        if i == anchor_promoter:  # mark anchor gene
                            seq.id += "__ANCHOR"  # must be part of id, otherwise MEME woun't recognize it
                        SeqIO.write(seq, pm_handle, "fasta")
            else:
                if VERBOSE_DEBUG:
                    logging.debug("Too short promoter set " + pm.pairing_string)
        else:
            if VERBOSE_DEBUG:
                logging.debug("Duplicate promoter set " + pm.pairing_string)

    return promoter_sets


def filter_meme_results(meme_dir: str, promoter_sets: List[Motif], anchor):
    """Analyse and filter MEME results"""
    for motif in promoter_sets:
        xml_file = os.path.join(meme_dir, motif.pairing_string, "meme.xml")
        e = ElementTree.parse(xml_file).getroot()
        reason = e.find("model/reason_for_stopping").text
        anchor_seq_id = ""

        # no motif found for given e-value cutoff :-(
        if "Stopped because motif E-value > " in reason:
            if VERBOSE_DEBUG:
                logging.debug("MEME: motif %s; e-value exceeds cutoff", motif.pairing_string)

        # motif(s) found :-)
        elif "Stopped because requested number of motifs (1) found" in reason:
            # find anchor genes' sequence_id
            training_set = e.findall("training_set/sequence")  # all promoter sequences passed to MEME
            for element in training_set:
                if "__ANCHOR" in element.attrib["name"]:
                    anchor_seq_id = element.attrib["id"]  # e.g. id=sequence_1

            # only accept motifs which occur in the anchor genes promoter
            # sequences which contributed to the motif
            contributing_sites = e.findall("motifs/motif/contributing_sites/contributing_site")
            if anchor_seq_id in map(lambda site: site.attrib["sequence_id"], contributing_sites):
                # save motif score
                motif.score = float(e.find("motifs/motif").attrib["e_value"])  # one motif, didn't ask MEME for more

                # save sequence sites which represent the motif
                motif.seqs = ["".join(map(lambda letter: letter.attrib["letter_id"],
                                          site.findall("site/letter_ref")))
                              for site in contributing_sites]
                # write sites to fasta file
                with open(os.path.join(meme_dir, str(motif),
                                       "binding_sites.fasta"), "w") as handle:
                    handle.write(">{}__{}\n".format(anchor, str(motif)))
                    handle.write("\n".join(motif.seqs))
                if VERBOSE_DEBUG:
                    logging.debug("MEME: motif %s; e-value = %s", motif, motif.score)
            else:
                if VERBOSE_DEBUG:
                    logging.debug("MEME: motif %s; does not occur in anchor gene promoter", motif)

        # unexpected reason, don't know why MEME stopped :-$
        else:
            logging.error("MEME stopped unexpectedly (reason: " + reason + ")")

    return [motif for motif in promoter_sets if motif.score is not None]


def filter_fimo_results(motifs: List[Motif], fimo_dir: str, promoters: List[Promoter],
                        anchor_promoter: int) -> List[Motif]:
    """Analyse and filter FIMO results"""

    filtered = []

    for motif in motifs:
        assert isinstance(motif, Motif), type(motif)
        with open(os.path.join(fimo_dir, str(motif), "fimo.txt"), "r") as handle:
            table_reader = csv.reader(handle, delimiter="\t")
            for row in table_reader:
                # skip comment lines
                if row[0].startswith("#"):
                    continue
                seq_id = row[1]
                motif.hits[seq_id] += 1

        # write binding sites per promoter to file
        with open(os.path.join(fimo_dir, str(motif), "bs_per_promoter.csv"), "w") as handle:
            table_writer = csv.writer(handle, delimiter="\t", lineterminator="\n")
            table_writer.writerow(["#", "promoter", "binding sites"])  # table head
            for i, promoter in enumerate(promoters):
                table_writer.writerow([i+1, promoter.get_id(), motif.hits.get(promoter.get_id(), 0)])

        percentage = len(motif.hits) / len(promoters) * 100
        if percentage == 0.0:
            # too low
            if VERBOSE_DEBUG:
                logging.debug("FIMO: motif %s; occurs in %d promoters (no hits)",
                              motif, len(motif.hits))
            continue
        elif percentage > MAX_PERCENTAGE:
            # too high
            if VERBOSE_DEBUG:
                logging.debug("FIMO: %s; occurs in %d promoters; %.2f%% of all promoters (too many)",
                              motif, len(motif.hits), percentage)
            continue
        elif promoters[anchor_promoter].get_id() not in motif.hits:  # not in achor promoter
            # no site in anchor promoter
            if VERBOSE_DEBUG:
                logging.debug("FIMO: motif %s; no hits in the promoter of the anchor gene", motif)
            continue

        # everything ok
        if VERBOSE_DEBUG:
            logging.debug("FIMO: motif %s; occurs in %d promoters; %.2f%% of all promoters",
                          motif, len(motif.hits), percentage)
        filtered.append(motif)

    return filtered


def get_islands(anchor_promoter: int, motifs: List[Motif], promoters: List[Promoter]):
    """Find islands of binding sites (previously found by FIMO) around anchor gene to define cluster borders"""
    islands = []
    motifs = list(motifs)
    for motif in motifs:
        # create list with binding sites per promoter
        bs_per_promoter = [0] * len(promoters)  # first: set number of binding sites to 0
        for i, promoter in enumerate(promoters):
            # second: set actual number of binding sites, if any
            bs_per_promoter[i] = motif.hits[promoter.get_id()]

        # upstream
        start = anchor_promoter  # init upstream cluster border
        i = anchor_promoter  # init position of anchor gene's promoter
        while i > 0:

            # promoter with binding site
            # … 1 …
            if bs_per_promoter[i-1] >= 1:
                start -= 1

            # no binding site, gap with length 1
            # … 1 0 1  …
            elif (i - 2 >= 0
                  and MAX_GAP_LENGTH >= 1
                  and bs_per_promoter[i] >= 1
                  and bs_per_promoter[i-1] == 0
                  and bs_per_promoter[i-2] >= 1):
                start -= 2
                i -= 1

            # no binding site, gap with length 2
            # … 1 0 0 1  …
            elif (i - 3 >= 0
                  and MAX_GAP_LENGTH >= 2
                  and bs_per_promoter[i] >= 1
                  and bs_per_promoter[i-1] == 0
                  and bs_per_promoter[i-2] == 0
                  and bs_per_promoter[i-3] >= 1):
                start -= 3
                i -= 2

            # no binding site, gap with length 3
            # … 1 0 0 0 1  …
            elif (i - 4 >= 0
                  and MAX_GAP_LENGTH >= 3
                  and bs_per_promoter[i] >= 1
                  and bs_per_promoter[i-1] == 0
                  and bs_per_promoter[i-2] == 0
                  and bs_per_promoter[i-3] == 0
                  and bs_per_promoter[i-4] >= 1):
                start -= 4
                i -= 3

            # no binding site, gap with length 4
            # … 1 0 0 0 0 1  …
            elif (i - 5 >= 0
                  and MAX_GAP_LENGTH >= 4
                  and bs_per_promoter[i] >= 1
                  and bs_per_promoter[i-1] == 0
                  and bs_per_promoter[i-2] == 0
                  and bs_per_promoter[i-3] == 0
                  and bs_per_promoter[i-4] == 0
                  and bs_per_promoter[i-5] >= 1):
                start -= 5
                i -= 4

            # no binding site, gap with length 5
            # … 1 0 0 0 0 0 1  …
            elif (i - 6 >= 0
                  and MAX_GAP_LENGTH >= 5
                  and bs_per_promoter[i] >= 1
                  and bs_per_promoter[i-1] == 0
                  and bs_per_promoter[i-2] == 0
                  and bs_per_promoter[i-3] == 0
                  and bs_per_promoter[i-4] == 0
                  and bs_per_promoter[i-5] == 0
                  and bs_per_promoter[i-6] >= 1):
                start -= 6
                i -= 5

            # gap too long, stop upstream cluster extension
            else:
                break

            i -= 1

        # downstream
        i = anchor_promoter  # reset position of anchor gene's promoter
        end = anchor_promoter  # init downstream cluster border
        while i < len(bs_per_promoter) - 1:

            # promoter with binding site(s)
            # … 1 …
            if bs_per_promoter[i+1] > 0:
                end += 1

            # no binding site, gap with length 1
            # … 1 0 1  …
            elif (i + 2 < len(bs_per_promoter)
                  and MAX_GAP_LENGTH >= 1
                  and bs_per_promoter[i] >= 1
                  and bs_per_promoter[i+1] == 0
                  and bs_per_promoter[i+2] >= 1):
                end += 2
                i += 1

            # no binding site, gap with length 2
            # … 1 0 0 1  …
            elif (i + 3 < len(bs_per_promoter)
                  and MAX_GAP_LENGTH >= 2
                  and bs_per_promoter[i] >= 1
                  and bs_per_promoter[i+1] == 0
                  and bs_per_promoter[i+2] == 0
                  and bs_per_promoter[i+3] >= 1):
                end += 3
                i += 2

            # no binding site, gap with length 3
            # … 1 0 0 0 1  …
            elif (i + 4 < len(bs_per_promoter)
                  and MAX_GAP_LENGTH >= 3
                  and bs_per_promoter[i] >= 1
                  and bs_per_promoter[i+1] == 0
                  and bs_per_promoter[i+2] == 0
                  and bs_per_promoter[i+3] == 0
                  and bs_per_promoter[i+4] >= 1):
                end += 4
                i += 3

            # no binding site, gap with length 4
            # … 1 0 0 0 0 1  …
            elif (i + 5 < len(bs_per_promoter)
                  and MAX_GAP_LENGTH >= 4
                  and bs_per_promoter[i] >= 1
                  and bs_per_promoter[i+1] == 0
                  and bs_per_promoter[i+2] == 0
                  and bs_per_promoter[i+3] == 0
                  and bs_per_promoter[i+4] == 0
                  and bs_per_promoter[i+5] >= 1):
                end += 5
                i += 4

            # no binding site, gap with length 5
            # … 1 0 0 0 0 0 1  …
            elif (i + 6 < len(bs_per_promoter)
                  and MAX_GAP_LENGTH >= 5
                  and bs_per_promoter[i] >= 1
                  and bs_per_promoter[i+1] == 0
                  and bs_per_promoter[i+2] == 0
                  and bs_per_promoter[i+3] == 0
                  and bs_per_promoter[i+4] == 0
                  and bs_per_promoter[i+5] == 0
                  and bs_per_promoter[i+6] >= 1):
                end += 6
                i += 5

            # gap too long, stop downstream cluster extension
            else:
                break

            i += 1
        if VERBOSE_DEBUG:
            logging.debug("Island %s -- %s (motif %s)", promoters[start].get_id(),
                          promoters[end].get_id(), motif)
        islands.append(Island(promoters[start], promoters[end], motif))

    return islands


class ClusterMarker(Pairing):
    """ Marks the start or end position for a cluster by gene and motif.
        Tracks abundance and the motif string (+n/-m) for that position.
    """
    def __init__(self, gene: str, motif: Motif) -> None:
        super().__init__(motif.plus, motif.minus)
        self.gene = str(gene)
        self.abundance = 1
        self.score = float(motif.score)
        self.promoter = None  # type: Optional[str]

    def update(self, motif) -> None:
        """ Uses the given motif's values instead of the old ones, if the given
            motif has a better (lower) score.
        """
        if self.score > float(motif.score):
            self.score = float(motif.score)
            self.plus = int(motif.plus)
            self.minus = int(motif.minus)

    def __str__(self) -> str:
        return "gene %s; abundance %s; motif %s; score %s" % (
                  self.gene, self.abundance, self.pairing_string, self.score)

    def __repr__(self) -> str:
        return "ClusterMarker(%s, promoter=%s)" % (str(self), self.promoter)

    def __eq__(self, other: Any) -> bool:
        return (isinstance(other, ClusterMarker)
                and all(getattr(self, key) == getattr(other, key) for key in vars(self)))


class ClusterPrediction:
    """ A prediction of a cluster. Contains start and end ClusterMarkers along with
        counts of genes and promoters within that range.
    """
    def __init__(self, start: ClusterMarker, end: ClusterMarker) -> None:
        self.start = start
        self.end = end
        self.genes = 0
        self.promoters = 0

    def __repr__(self) -> str:
        return "ClusterPrediction(start=%s, end=%s, gene_count=%d, promoter_count=%d)" % (
                        self.start, self.end, self.genes, self.promoters)

    def __eq__(self, other: Any) -> bool:
        return (isinstance(other, ClusterPrediction)
                and all(getattr(self, key) == getattr(other, key) for key in vars(self)))


def sort_by_abundance(islands: List[Island]) -> List[ClusterPrediction]:
    """Sort upstream (start) and downstream (end) borders of islands by abundance"""
    # count border abundance
    # start/end are treated independently!
    starts = {}  # type: Dict[str, ClusterMarker]
    ends = {}  # type: Dict[str, ClusterMarker]
    for island in islands:
        if island.start.gene_name in starts:
            scorer = starts[island.start.gene_name]
            scorer.abundance += 1
            scorer.update(island.motif)
        else:
            starts[island.start.gene_name] = ClusterMarker(island.start.gene_name, island.motif)

        if island.end.get_gene_names()[-1] in ends:
            scorer = ends[island.end.get_gene_names()[-1]]
            scorer.abundance += 1
            scorer.update(island.motif)
        else:
            ends[island.end.get_gene_names()[-1]] = ClusterMarker(island.end.get_gene_names()[-1], island.motif)

    # compute sum of start and end abundance, remove duplicates, sort descending
    abundances_sum_sorted = sorted(set([s.abundance + e.abundance
                                        for s in starts.values() for e in ends.values()]), reverse=True)
    # compute sum of start and end motif score, remove duplicates, sort ascending
    scores_sum_sorted = sorted(set([s.score + e.score
                                    for s in starts.values() for e in ends.values()]))
    # sort by value (=abundance) of start, descending
    starts_sorted = sorted(starts, key=lambda x: starts[x].abundance, reverse=True)
    # sort by value (=abundance) of end, descending
    ends_sorted = sorted(ends, key=lambda x: ends[x].abundance, reverse=True)

    clusters = []
    for abundance in abundances_sum_sorted:
        # list from highest (best) to lowest (worst) abundance
        for score in scores_sum_sorted:
            # list from lowest (best) to highest (worst) motif score/e-value
            for start in starts_sorted:
                for end in ends_sorted:
                    if (starts[start].abundance + ends[end].abundance == abundance
                            and starts[start].score + ends[end].score == score):
                        start_marker = starts[start]
                        end_marker = ends[end]
                        clusters.append(ClusterPrediction(start_marker, end_marker))
                        if VERBOSE_DEBUG:
                            logging.debug("Upstream border:   %s", start_marker)
                            logging.debug("Downstream border: %s", end_marker)
                            logging.debug("Total abundance %s, total score %.1e", abundance, score)
    return clusters


def check_cluster_predictions(cluster_predictions: List[ClusterPrediction],
                              record: Record, promoters: List[Promoter], ignored_genes: List[Gene]):
    """Get some more info about each cluster prediction and check if it is sane"""
    checked_predictions = []
    for cp, prediction in enumerate(cluster_predictions):
        sane = True

        # find indices of first and last GENE of the cluster prediction in all genes
        all_gene_names = [gene.get_name() for gene in sorted(record.get_genes(), key=lambda x: x.location.start)]

        start_index_genes = None
        end_index_genes = None
        for i, gene_name in enumerate(all_gene_names):
            if not start_index_genes and prediction.start.gene == gene_name:
                start_index_genes = i
            if not end_index_genes and prediction.end.gene == gene_name:
                end_index_genes = i
            if start_index_genes and end_index_genes:
                break

        # find indices of first and last PROMOTER of the cluster prediction in all promoters
        start_index_promoters = None
        end_index_promoters = None
        for i, promoter in enumerate(promoters):
            if not start_index_promoters and prediction.start.gene in promoter.get_gene_names():
                start_index_promoters = i
            if not end_index_promoters and prediction.end.gene in promoter.get_gene_names():
                end_index_promoters = i
            if start_index_promoters and end_index_promoters:
                break

        prediction.start.promoter = promoters[start_index_promoters].get_id()
        prediction.end.promoter = promoters[end_index_promoters].get_id()
        prediction.genes = end_index_genes - start_index_genes + 1
        prediction.promoters = end_index_promoters - start_index_promoters + 1
        if VERBOSE_DEBUG:
            if cp == 0:
                logging.debug("Best prediction (most abundant): %r -- %r",
                             prediction.start.gene, prediction.end.gene)
            else:
                logging.debug("Alternative prediction (%s): %r -- %r",
                             cp, prediction.start.gene, prediction.end.gene)

        # warn if cluster prediction right at or next to record (~ contig) border
        if start_index_genes < 10:
            if VERBOSE_DEBUG:
                logging.debug("Upstream cluster border located at or next to sequence record border,"
                              " prediction could have been truncated by record border")
            sane = False
        if end_index_genes > len(all_gene_names) - 10:
            if VERBOSE_DEBUG:
                logging.debug("Downstream cluster border located at or next to sequence record border,"
                              " prediction could have been truncated by record border")
            sane = False

        # warn if cluster prediction too short (includes less than 3 genes)
        if prediction.genes < 3:
            if VERBOSE_DEBUG:
                logging.debug("Cluster is very short (less than 3 genes). Prediction may be questionable.")
            sane = False

        # warn if ignored gene (overlapping with anthor gene, see ignore_overlapping())
        # would have been part of the cluster
        for ignored_gene in ignored_genes:
            if ignored_gene.get_name() in all_gene_names[start_index_genes: end_index_genes + 1]:
                if VERBOSE_DEBUG:
                    logging.debug("Gene %r is part of the predicted cluster,"
                                 " but it is overlapping with another gene and was ignored", ignored_gene)
                    logging.debug("Gene %r could have affected the cluster prediction", ignored_gene)
                # sane = False # uncomment if you want alternatives for predictions with ignored genes, too # TODO
                break

        checked_predictions.append(prediction)

        if sane:  # TODO: this seems wrong
            break
    return checked_predictions


def cleanup_outdir(anchor_gene_names: List[str], cluster_predictions: Dict[str, List[ClusterPrediction]], options):
    """Delete unnecessary files to free disk space"""
    all_motifs = set()
    for motif in PROMOTER_RANGE:
        all_motifs.add(motif.pairing_string)

    for anchor in anchor_gene_names:
        if anchor in cluster_predictions:
            used_motifs = set()
            for cluster in cluster_predictions[anchor]:
                used_motifs.add(cluster.start.pairing_string)
                used_motifs.add(cluster.end.pairing_string)
            unused_motifs = all_motifs.difference(used_motifs)
            # only remove directories from "unused" motifs (no cluster prediction)
            for directory in unused_motifs:
                shutil.rmtree(os.path.join(options.output_dir, "meme", anchor, directory), ignore_errors=True)
                shutil.rmtree(os.path.join(options.output_dir, "fimo", anchor, directory), ignore_errors=True)
        else:
            # all motifs are "unused" (not a single prediction for this anchor gene)
            # --> remove anchor genes directory, including all motif subdirectories
            shutil.rmtree(os.path.join(options.output_dir, "meme", anchor), ignore_errors=True)
            shutil.rmtree(os.path.join(options.output_dir, "fimo", anchor), ignore_errors=True)


# storage methods
def store_promoters(promoters, record: Record):
    """Store information about promoter sequences to a SeqRecord"""
    logging.critical("adding promoters based on biopython features")
    for promoter in promoters:
        # remember to account for 0-indexed start location
        new_feature = SeqFeature(FeatureLocation(max(0, promoter.start - 1), promoter.end),
                                 type="promoter")
        new_feature.qualifiers = {
            "locus_tag": promoter.get_gene_names(),  # already a list with one or two elements
            "seq": [str(promoter.seq)],  # TODO save string or Seq object?
        }

        if isinstance(promoter, CombinedPromoter):
            new_feature.qualifiers["note"] = ["bidirectional promoter"]

        secmet_version = Feature.from_biopython(new_feature)
        secmet_version.created_by_antismash = True

        record.add_feature(secmet_version)


def create_cluster_borders(anchor: str, clusters: List[ClusterPrediction],
                           record: Record) -> List[ClusterBorder]:
    """ Create the predicted ClusterBorders """
    if not clusters:
        return []
    logging.critical("still constructing biopython features for cluster borders")
    borders = []
    for i, cluster in enumerate(clusters):
        # cluster borders returned by hmmdetect are based on CDS features
        # in contrast, cluster borders returned by cassis are based on gene features
        # --> hmmdetect derived clusters have exact loctions, like the CDSs have
        # --> cassis derived clusters may have fuzzy locations, like the genes have
        #
        # utils.get_all_features_of_type_with_query() returns a list
        # there should be no second gene with the same locus tag
        # --> always take the first [0] element of the return value
        left_name = cluster.start.gene
        right_name = cluster.end.gene
        left = None
        right = None
        for gene in record.get_genes():
            if gene.get_name() == left_name:
                left = gene
            if gene.get_name() == right_name:
                right = gene
            if left and right:
                break

        new_feature = SeqFeature(
            FeatureLocation(left.location.start, right.location.end), type="cluster_border")
        new_feature.qualifiers = {
            "aStool": ["cassis"],
            "anchor": [anchor],
            "abundance": [cluster.start.abundance + cluster.end.abundance],
            "motif_score": ["{:.1e}".format(cluster.start.score + cluster.end.score)],
            "gene_left": [cluster.start.gene],
            "promoter_left": [cluster.start.promoter],
            "abundance_left": [cluster.start.abundance],
            "motif_left": [cluster.start.pairing_string],
            "motif_score_left": ["{:.1e}".format(cluster.start.score)],
            "gene_right": [cluster.end.gene],
            "promoter_right": [cluster.end.promoter],
            "abundance_right": [cluster.end.abundance],
            "motif_right": [cluster.end.pairing_string],
            "motif_score_right": ["{:.1e}".format(cluster.end.score)],
            "genes": [cluster.genes],
            "promoters": [cluster.promoters],
        }

        if i == 0:
            new_feature.qualifiers["note"] = ["best prediction (most abundant) for anchor gene {}".format(anchor)]
        else:
            new_feature.qualifiers["note"] = ["alternative prediction ({}) for anchor gene {}".format(i, anchor)]

        new_feature = ClusterBorder.from_biopython(new_feature)
        borders.append(new_feature)
    return borders
